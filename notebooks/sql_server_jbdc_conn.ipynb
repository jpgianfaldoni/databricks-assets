{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9fc5d8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# JDBC connection properties\n",
    "jdbc_hostname = \"your_sql_server_hostname\"\n",
    "jdbc_port = 1433\n",
    "jdbc_database = \"your_database_name\"\n",
    "jdbc_username = \"your_username\"\n",
    "jdbc_password = \"your_password\" # It is recommended to use Databricks secrets to store credentials\n",
    "\n",
    "# Create the JDBC URL\n",
    "jdbc_url = f\"jdbc:sqlserver://{jdbc_hostname}:{jdbc_port};databaseName={jdbc_database}\"\n",
    "\n",
    "# Name of the table to query\n",
    "table_name = \"your_table_name\"\n",
    "\n",
    "# Read data from SQL Server into a DataFrame\n",
    "try:\n",
    "    df = (spark.read\n",
    "          .format(\"jdbc\")\n",
    "          .option(\"url\", jdbc_url)\n",
    "          .option(\"dbtable\", table_name)\n",
    "          .option(\"user\", jdbc_username)\n",
    "          .option(\"password\", jdbc_password)\n",
    "          .load())\n",
    "\n",
    "    # Show the first few rows of the DataFrame\n",
    "    print(\"Successfully loaded data from the table.\")\n",
    "    df.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
